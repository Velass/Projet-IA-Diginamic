import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import (
    neural_network,
    pipeline,
    metrics,
    model_selection,
    preprocessing,
    tree,
    ensemble
)

st.set_page_config(page_title="Machine Learning et Ã‰valuation", page_icon="ğŸ¤–")

df_raw = pd.read_csv("./data/vin.csv", sep=",").iloc[:, 1:]
st.title("Machine Learning et Ã‰valuation")

st.markdown(
    """
Bienvenue dans la section Machine Learning.  
ğŸ“Œ **Choisissez une approche :**
"""
)

sous_page = st.radio(
    "ğŸ”¹ SÃ©lectionnez une mÃ©thode :", ["Arbre de DÃ©cision", "RÃ©seau de Neurones", "Foret Aleatoire"]
)

if sous_page == "Arbre de DÃ©cision":
    st.markdown("## ğŸŒ³ Arbre de DÃ©cision")
    st.write("Nous allons maintenant entraÃ®ner un **arbre de dÃ©cision**.")

    df_raw["target"] = df_raw["target"].map(
        {"Vin sucrÃ©": 0, "Vin Ã©uilibrÃ©": 1, "Vin amer": 2}
    )

    target = ["target"]
    features = [col for col in df_raw.columns if col not in target]

    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        df_raw[features], df_raw[target], test_size=0.2, random_state=42
    )

    st.title("Machine Learning et Evaluation")
    st.markdown("## donnÃ©es pret.")
    st.write(
        "nous pouvons donc voir que les donnÃ©es sont prÃªtes pour le machine learning et ci-dessous les different pourcentage pour notre target."
    )
    st.write(y_train["target"].value_counts(normalize=True))

    st.markdown("## EntraÃ®nement d'un arbre de dÃ©cision")
    pipe = pipeline.Pipeline(
        [
            # ("feature_selection", feature_selection),
            # ('std_scaler', preprocessing.StandardScaler()),
            ("decision_tree", tree.DecisionTreeClassifier())
        ]
    )
    pipe.fit(X_train, y_train)
    st.write(
        "Nous allons maintenant entraÃ®ner un arbre de dÃ©cision sur nos donnÃ©es.\n"
        "Nous avons crÃ©Ã© et entraÃ®nÃ© un pipeline qui contient un arbre de dÃ©cision.\n"
        "Nous pouvons maintenant l'Ã©valuer."
    )
    train_acc = pipe.score(X_train, y_train)
    test_acc = pipe.score(X_test, y_test)

    st.markdown(
        f"""
    **ğŸ“Š Accuracy sur le train set :** `{train_acc:.4f}`  
    **ğŸ“Š Accuracy sur le test set :** `{test_acc:.4f}`
    """
    )

    st.markdown("### ğŸŒ³ Visualisation de l'Arbre de DÃ©cision")

    fig, ax = plt.subplots(figsize=(12, 6))
    tree.plot_tree(
        pipe.named_steps["decision_tree"],  # Utilisation du bon index dans le pipeline
        feature_names=X_train.columns,
        filled=True,
        rounded=True,
        class_names=["Vin sucrÃ©", "Vin Ã©quilibrÃ©", "Vin amer"],
        fontsize=8,
        ax=ax,
    )

    st.pyplot(fig)

    st.markdown("### ğŸ“Š Matrice de Confusion")
    # with st.expander("Matrice de confusion", expanded=False):
    cm_display = metrics.ConfusionMatrixDisplay.from_predictions(
        y_test, pipe.predict(X_test)
    )
    fig, ax = plt.subplots(figsize=(3, 2))
    cm_display.plot(ax=ax, cmap="Blues", colorbar=True)
    st.pyplot(fig, use_container_width=False)

    st.markdown("### ğŸ“„ Rapport de Classification")
    report = metrics.classification_report(y_test, pipe.predict(X_test))
    st.code(report, language="text")


if sous_page == "RÃ©seau de Neurones":
    st.markdown("## ğŸ§  RÃ©seau de Neurones")
    st.write("Nous allons maintenant entraÃ®ner un **rÃ©seau de neurones**.")

    df_raw["target"] = df_raw["target"].map(
        {"Vin sucrÃ©": 0, "Vin Ã©uilibrÃ©": 1, "Vin amer": 2}
    )

    target = ["target"]
    features = [col for col in df_raw.columns if col not in target]

    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        df_raw[features], df_raw[target], test_size=0.2, random_state=42
    )

    st.title("Machine Learning et Evaluation")
    st.markdown("## donnÃ©es pret.")
    st.write(
        "nous pouvons donc voir que les donnÃ©es sont prÃªtes pour le machine learning et ci-dessous les different pourcentage pour notre target."
    )
    st.write(y_train["target"].value_counts(normalize=True))

    st.markdown("## EntraÃ®nement d'un RÃ©seau de Neurones")
    pipe = pipeline.Pipeline(
        [
            # ("feature_selection", feature_selection),
            ("std_scaler", preprocessing.StandardScaler()),
            ("neural_network", neural_network.MLPClassifier()),
        ]
    )
    pipe.fit(X_train, y_train)
    st.write(
        "Nous allons maintenant entraÃ®ner un rÃ©seau de neurones sur nos donnÃ©es.\n"
        "Nous avons crÃ©Ã© et entraÃ®nÃ© un pipeline qui contient un rÃ©seau de neurones.\n"
        "Nous pouvons maintenant l'Ã©valuer."
    )
    train_acc = pipe.score(X_train, y_train)
    test_acc = pipe.score(X_test, y_test)

    st.markdown(
        f"""
    **ğŸ“Š Accuracy sur le train set :** `{train_acc:}`  
    **ğŸ“Š Accuracy sur le test set :** `{test_acc}`
    """
    )

    st.markdown("### Visualisation RÃ©seau de Neurones")

    st.markdown("### Nombre de Neurones")
# VÃ©rifier si le modÃ¨le contient un rÃ©seau de neurones
    if "neural_network" in pipe.named_steps:
        hidden_layers = pipe.named_steps["neural_network"].hidden_layer_sizes

        # Affichage du nombre de neurones par couche
        st.write("### ğŸ§  Nombre de neurones par couche du RÃ©seau de Neurones :")
        st.write(f"ğŸ“Œ Couches cachÃ©es : {hidden_layers}")
        st.write(
            f"ğŸ“Œ Nombre total de couches (y compris entrÃ©e et sortie) : {len(hidden_layers) + 2}"
        )

        st.markdown("### ğŸ“Š Matrice de Confusion")
        # with st.expander("Matrice de confusion", expanded=False):
        cm_display = metrics.ConfusionMatrixDisplay.from_predictions(
            y_test, pipe.predict(X_test)
        )
        fig, ax = plt.subplots(figsize=(3, 2))
        cm_display.plot(ax=ax, cmap="Blues", colorbar=True)
        st.pyplot(fig, use_container_width=False)

        st.markdown("### ğŸ“„ Rapport de Classification")
        report = metrics.classification_report(y_test, pipe.predict(X_test))
        st.code(report, language="text")
    
if sous_page == "Foret Aleatoire":
    st.markdown("## ğŸŒ³ğŸŒ³ Foret Aleatoire")
    st.write("Nous allons maintenant entraÃ®ner une **Foret Aleatoire**.")
    
    df_raw["target"] = df_raw["target"].map(
        {"Vin sucrÃ©": 0, "Vin Ã©uilibrÃ©": 1, "Vin amer": 2}
    )
    target = ["target"]
    features = [col for col in df_raw.columns if col not in target]

    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        df_raw[features], df_raw[target], test_size=0.2, random_state=42
    )

    st.title("Machine Learning et Evaluation")
    st.markdown("## les donnÃ©es sont pretes.")
    st.write(
        "nous pouvons donc voir que les donnÃ©es sont prÃªtes pour le machine learning et ci-dessous les different pourcentage pour notre target."
    )
    st.write(y_train["target"].value_counts(normalize=True))

    st.markdown("## EntraÃ®nement de la Foret Aleatoire")
    pipe = pipeline.Pipeline(
        [
            ('std_scaler', preprocessing.StandardScaler()),
            ("random_forest", ensemble.RandomForestClassifier())
        ]
    )
    pipe.fit(X_train, y_train)
    st.write(
        "Nous allons maintenant entraÃ®ner un arbre de dÃ©cision sur nos donnÃ©es.\n"
        "Nous avons crÃ©Ã© et entraÃ®nÃ© un pipeline qui contient un arbre de dÃ©cision.\n"
        "Nous pouvons maintenant l'Ã©valuer."
    )
    train_acc = pipe.score(X_train, y_train)
    test_acc = pipe.score(X_test, y_test)

    st.markdown(
        f"""
    **ğŸ“Š Accuracy sur le train set :** `{train_acc}`  
    **ğŸ“Š Accuracy sur le test set :** `{test_acc}`
    """
    )

if "random_forest" in pipe.named_steps:
    rf_model = pipe.named_steps["random_forest"]
    
    st.markdown("### ğŸŒ³ğŸŒ³ Visualisation de plusieurs Arbres de la ForÃªt AlÃ©atoire")

    # CrÃ©ation de la figure
    fig, axes = plt.subplots(2, 2, figsize=(26, 18))  # Grille de 2x2
    axes = axes.ravel()  # Aplatir la grille en 1D pour itÃ©rer facilement
    n_trees = min(4, len(rf_model.estimators_)) 
    for i in range(n_trees):
        tree.plot_tree(
            rf_model.estimators_[i],
            feature_names=X_train.columns,
            filled=True,
            rounded=True,
            class_names=["Vin sucrÃ©", "Vin Ã©quilibrÃ©", "Vin amer"],
            fontsize=6,
            ax=axes[i]  # Utiliser un sous-plot
        )
        axes[i].set_title(f"Arbre {i+1}")

    st.pyplot(fig)
    
    st.markdown("### ğŸ“Š Matrice de Confusion")
    cm_display = metrics.ConfusionMatrixDisplay.from_predictions(
        y_test, pipe.predict(X_test)
    )
    fig, ax = plt.subplots(figsize=(3, 2))
    cm_display.plot(ax=ax, cmap="Blues", colorbar=True)
    st.pyplot(fig, use_container_width=False)

    st.markdown("### ğŸ“„ Rapport de Classification")
    report = metrics.classification_report(y_test, pipe.predict(X_test))
    st.code(report, language="text")